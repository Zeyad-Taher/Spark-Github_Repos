{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import count, col, sum, input_file_name, regexp_extract, regexp_replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_url = \"jdbc:oracle:thin:@//localhost:1521:ORCL\"\n",
    "db_properties = {\n",
    "    \"user\": \"system\",\n",
    "    \"password\": \"orcl1234\",\n",
    "    \"driver\": \"oracle.jdbc.OracleDriver\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"GitHubRepos\") \\\n",
    ".getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.json(['data/Angular.json','data/Cpp.json','data/Dart.json','data/Deep-Learning.json','data/Django.json','data/Docker.json','data/ethereum.json','data/Flask.json','data/Flutter.json','data/Gatsby.json','data/Golang.json','data/Hadoop.json','data/Hadoop.json','data/Julia.json','data/Kotlin.json','data/Kubernetes.json','data/Machine-Learning.json','data/NextJS.json','data/NodeJS.json','data/OOPs.json','data/PyTorch.json','data/R.json','data/React-JS.json','data/React-Native.json','data/Scala.json','data/Scikit.json','data/serverless.json','data/Spark.json','data/Tensorflow.json','data/Threejs.json','data/Typescript.json'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"file_name\", regexp_extract(input_file_name(), r\"([^/\\\\]+)$\", 1))\n",
    "df = df.withColumn(\"file_name\", regexp_replace(col(\"file_name\"), r\"\\.json$\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _corrupt_record: string (nullable = true)\n",
      " |-- created: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      " |-- forks: long (nullable = true)\n",
      " |-- full_name: string (nullable = true)\n",
      " |-- id: long (nullable = true)\n",
      " |-- language: string (nullable = true)\n",
      " |-- open_issues: long (nullable = true)\n",
      " |-- repo_name: string (nullable = true)\n",
      " |-- stars: long (nullable = true)\n",
      " |-- subscribers: long (nullable = true)\n",
      " |-- topics: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- username: string (nullable = true)\n",
      " |-- file_name: string (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------------+--------------------+-----+--------------------+---------+----------------+-----------+--------------------+-----+-----------+--------------------+------------+-------------------+---------+\n",
      "|_corrupt_record|            created|         description|forks|           full_name|       id|        language|open_issues|           repo_name|stars|subscribers|              topics|        type|           username|file_name|\n",
      "+---------------+-------------------+--------------------+-----+--------------------+---------+----------------+-----------+--------------------+-----+-----------+--------------------+------------+-------------------+---------+\n",
      "|           NULL|2014-02-25 08:00:08|Apache Spark - A ...|25357|        apache/spark| 17165658|           Scala|        242|               spark|32296|       2080|[python, scala, r...|Organization|             apache|    Spark|\n",
      "|           NULL|2017-08-09 19:39:59|Distributed train...| 2027|     horovod/horovod| 99846383|          Python|        298|             horovod|12219|        334|[tensorflow, uber...|Organization|            horovod|    Spark|\n",
      "|           NULL|2014-08-08 07:30:51|Notes talking abo...| 1773|JerryLead/SparkIn...| 22749672|            NULL|         27|      SparkInternals| 4774|        619|                  []|        User|          JerryLead|    Spark|\n",
      "|           NULL|2019-04-22 18:56:51|An open-source st...|  985|      delta-io/delta|182849188|           Scala|        180|               delta| 4164|        188|[spark, acid, big...|Organization|           delta-io|    Spark|\n",
      "|           NULL|2017-01-20 18:15:57|TensorFlowOnSpark...|  966|yahoo/TensorFlowO...| 79584587|          Python|          6|   TensorFlowOnSpark| 3768|        286|[tensorflow, spar...|Organization|              yahoo|    Spark|\n",
      "|           NULL|2019-01-03 21:46:54|Koalas: pandas AP...|  333|   databricks/koalas|164026325|          Python|        103|              koalas| 3095|        222|[spark, pandas, p...|Organization|         databricks|    Spark|\n",
      "|           NULL|2014-08-21 23:07:47|REST job server f...| 1003|spark-jobserver/s...| 23205911|           Scala|        106|     spark-jobserver| 2767|        219|[spark, rest-api,...|Organization|    spark-jobserver|    Spark|\n",
      "|           NULL|2017-05-05 02:27:30|Distributed Tenso...|  714|intel-analytics/a...| 90328920|Jupyter Notebook|        560|       analytics-zoo| 2483|        102|[apache-spark, de...|Organization|    intel-analytics|    Spark|\n",
      "|           NULL|2019-07-04 17:09:41|Distributed compu...|  148|ballista-compute/...|195277793|            Rust|          0|            ballista| 2285|         71|[rust, arrow, dat...|Organization|   ballista-compute|    Spark|\n",
      "|           NULL|2018-08-07 20:55:14|Deequ is a librar...|  389|       awslabs/deequ|143925946|           Scala|        103|               deequ| 2158|         70|[dataquality, spa...|Organization|            awslabs|    Spark|\n",
      "|           NULL|2017-11-02 16:15:15|TransmogrifAI (pr...|  374|salesforce/Transm...|109289451|           Scala|         44|       TransmogrifAI| 2101|        146|[ml, automl, tran...|Organization|         salesforce|    Spark|\n",
      "|           NULL|2019-10-22 19:13:09|A new arguably fa...|  179|     rajasekarv/vega|216890889|            Rust|         34|                vega| 2028|        116|                  []|        User|         rajasekarv|    Spark|\n",
      "|           NULL|2017-05-31 17:30:28|Deep Learning Pip...|  494|databricks/spark-...| 92971378|          Python|         85| spark-deep-learning| 1912|        151|                  []|Organization|         databricks|    Spark|\n",
      "|           NULL|2018-01-03 17:43:16|Kubernetes operat...|  921|GoogleCloudPlatfo...|116165188|              Go|        327|spark-on-k8s-oper...| 1895|         82|[kubernetes, kube...|Organization|GoogleCloudPlatform|    Spark|\n",
      "|           NULL|2014-07-25 20:08:44|Oryx 2: Lambda ar...|  412|    OryxProject/oryx| 22269384|            Java|          1|                oryx| 1796|        214|[lambda-architect...|Organization|        OryxProject|    Spark|\n",
      "|           NULL|2019-04-22 18:55:55|.NET for ApacheÂ® ...|  270|        dotnet/spark|182849051|              C#|        140|               spark| 1746|         82|[spark, csharp, d...|Organization|             dotnet|    Spark|\n",
      "|           NULL|2015-10-08 12:19:32|Apache Spark dock...|  593|big-data-europe/d...| 43886361|           Shell|         38|        docker-spark| 1706|         99|[spark-kubernetes...|Organization|    big-data-europe|    Spark|\n",
      "|           NULL|2015-08-22 13:52:08|Elassandra = Elas...|  204|strapdata/elassandra| 41209174|            Java|         40|          elassandra| 1624|         87|[cassandra, elast...|Organization|          strapdata|    Spark|\n",
      "|           NULL|2015-05-06 07:45:21|Apache Spark & Py...|  893|jadianes/spark-py...| 35145949|Jupyter Notebook|          9|  spark-py-notebooks| 1439|         99|[spark, python, p...|        User|           jadianes|    Spark|\n",
      "|           NULL|2016-06-28 07:00:06|High performance ...|  697|   apache/carbondata| 62117818|           Scala|        138|          carbondata| 1309|        129|[scala, java, big...|Organization|             apache|    Spark|\n",
      "+---------------+-------------------+--------------------+-----+--------------------+---------+----------------+-----------+--------------------+-----+-----------+--------------------+------------+-------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PROGRAMMING_LANG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_languages = df.groupBy('language').agg(count(\"*\").alias('NUM_OF_REPOS'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+\n",
      "|  language|NUM_OF_REPOS|\n",
      "+----------+------------+\n",
      "|        C#|         342|\n",
      "|     Terra|           1|\n",
      "|  Makefile|          38|\n",
      "|       VBA|           4|\n",
      "|      Cuda|          12|\n",
      "|       Arc|           2|\n",
      "|      LLVM|           2|\n",
      "|      Rust|         167|\n",
      "|JavaScript|        5318|\n",
      "|      TSQL|          11|\n",
      "|      Perl|          16|\n",
      "|    Puppet|           7|\n",
      "|    Erlang|           7|\n",
      "|      NULL|        1503|\n",
      "|     Jinja|          15|\n",
      "|       C++|         958|\n",
      "|        F#|           3|\n",
      "|    Groovy|          20|\n",
      "|       TeX|          44|\n",
      "|     OCaml|          16|\n",
      "+----------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_languages.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prog_lang =  df_languages.filter(col(\"language\").isNotNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+\n",
      "|  language|NUM_OF_REPOS|\n",
      "+----------+------------+\n",
      "|        C#|         342|\n",
      "|     Terra|           1|\n",
      "|  Makefile|          38|\n",
      "|       VBA|           4|\n",
      "|      Cuda|          12|\n",
      "|       Arc|           2|\n",
      "|      LLVM|           2|\n",
      "|      Rust|         167|\n",
      "|JavaScript|        5318|\n",
      "|      TSQL|          11|\n",
      "|      Perl|          16|\n",
      "|    Puppet|           7|\n",
      "|    Erlang|           7|\n",
      "|     Jinja|          15|\n",
      "|       C++|         958|\n",
      "|        F#|           3|\n",
      "|    Groovy|          20|\n",
      "|       TeX|          44|\n",
      "|     OCaml|          16|\n",
      "|      MQL5|           1|\n",
      "+----------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_prog_lang.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prog_lang.write.jdbc(url=db_url, table=\"PROGRAMMING_LANG\", mode=\"overwrite\", properties=db_properties)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ORGNIZATION_TYPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_org_type = df.filter(col(\"type\")==\"Organization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------------+--------------------+-----+--------------------+---------+----------------+-----------+--------------------+-----+-----------+--------------------+------------+-------------------+---------+\n",
      "|_corrupt_record|            created|         description|forks|           full_name|       id|        language|open_issues|           repo_name|stars|subscribers|              topics|        type|           username|file_name|\n",
      "+---------------+-------------------+--------------------+-----+--------------------+---------+----------------+-----------+--------------------+-----+-----------+--------------------+------------+-------------------+---------+\n",
      "|           NULL|2014-02-25 08:00:08|Apache Spark - A ...|25357|        apache/spark| 17165658|           Scala|        242|               spark|32296|       2080|[python, scala, r...|Organization|             apache|    Spark|\n",
      "|           NULL|2017-08-09 19:39:59|Distributed train...| 2027|     horovod/horovod| 99846383|          Python|        298|             horovod|12219|        334|[tensorflow, uber...|Organization|            horovod|    Spark|\n",
      "|           NULL|2019-04-22 18:56:51|An open-source st...|  985|      delta-io/delta|182849188|           Scala|        180|               delta| 4164|        188|[spark, acid, big...|Organization|           delta-io|    Spark|\n",
      "|           NULL|2017-01-20 18:15:57|TensorFlowOnSpark...|  966|yahoo/TensorFlowO...| 79584587|          Python|          6|   TensorFlowOnSpark| 3768|        286|[tensorflow, spar...|Organization|              yahoo|    Spark|\n",
      "|           NULL|2019-01-03 21:46:54|Koalas: pandas AP...|  333|   databricks/koalas|164026325|          Python|        103|              koalas| 3095|        222|[spark, pandas, p...|Organization|         databricks|    Spark|\n",
      "|           NULL|2014-08-21 23:07:47|REST job server f...| 1003|spark-jobserver/s...| 23205911|           Scala|        106|     spark-jobserver| 2767|        219|[spark, rest-api,...|Organization|    spark-jobserver|    Spark|\n",
      "|           NULL|2017-05-05 02:27:30|Distributed Tenso...|  714|intel-analytics/a...| 90328920|Jupyter Notebook|        560|       analytics-zoo| 2483|        102|[apache-spark, de...|Organization|    intel-analytics|    Spark|\n",
      "|           NULL|2019-07-04 17:09:41|Distributed compu...|  148|ballista-compute/...|195277793|            Rust|          0|            ballista| 2285|         71|[rust, arrow, dat...|Organization|   ballista-compute|    Spark|\n",
      "|           NULL|2018-08-07 20:55:14|Deequ is a librar...|  389|       awslabs/deequ|143925946|           Scala|        103|               deequ| 2158|         70|[dataquality, spa...|Organization|            awslabs|    Spark|\n",
      "|           NULL|2017-11-02 16:15:15|TransmogrifAI (pr...|  374|salesforce/Transm...|109289451|           Scala|         44|       TransmogrifAI| 2101|        146|[ml, automl, tran...|Organization|         salesforce|    Spark|\n",
      "|           NULL|2017-05-31 17:30:28|Deep Learning Pip...|  494|databricks/spark-...| 92971378|          Python|         85| spark-deep-learning| 1912|        151|                  []|Organization|         databricks|    Spark|\n",
      "|           NULL|2018-01-03 17:43:16|Kubernetes operat...|  921|GoogleCloudPlatfo...|116165188|              Go|        327|spark-on-k8s-oper...| 1895|         82|[kubernetes, kube...|Organization|GoogleCloudPlatform|    Spark|\n",
      "|           NULL|2014-07-25 20:08:44|Oryx 2: Lambda ar...|  412|    OryxProject/oryx| 22269384|            Java|          1|                oryx| 1796|        214|[lambda-architect...|Organization|        OryxProject|    Spark|\n",
      "|           NULL|2019-04-22 18:55:55|.NET for ApacheÂ® ...|  270|        dotnet/spark|182849051|              C#|        140|               spark| 1746|         82|[spark, csharp, d...|Organization|             dotnet|    Spark|\n",
      "|           NULL|2015-10-08 12:19:32|Apache Spark dock...|  593|big-data-europe/d...| 43886361|           Shell|         38|        docker-spark| 1706|         99|[spark-kubernetes...|Organization|    big-data-europe|    Spark|\n",
      "|           NULL|2015-08-22 13:52:08|Elassandra = Elas...|  204|strapdata/elassandra| 41209174|            Java|         40|          elassandra| 1624|         87|[cassandra, elast...|Organization|          strapdata|    Spark|\n",
      "|           NULL|2016-06-28 07:00:06|High performance ...|  697|   apache/carbondata| 62117818|           Scala|        138|          carbondata| 1309|        129|[scala, java, big...|Organization|             apache|    Spark|\n",
      "|           NULL|2016-02-01 18:15:42|A curated list of...|  303|awesome-spark/awe...| 50860011|           Shell|         19|       awesome-spark| 1280|         82|[apache-spark, py...|Organization|      awesome-spark|    Spark|\n",
      "|           NULL|2016-03-02 17:51:13|Dr. Elephant is a...|  817|linkedin/dr-elephant| 52983941|            Java|        167|         dr-elephant| 1253|        127|                  []|Organization|           linkedin|    Spark|\n",
      "|           NULL|2015-08-31 06:50:59|The Internals of ...|  418|japila-books/apac...| 41660382|            NULL|          7|apache-spark-inte...| 1191|        131|[apache-spark, sp...|Organization|       japila-books|    Spark|\n",
      "+---------------+-------------------+--------------------+-----+--------------------+---------+----------------+-----------+--------------------+-----+-----------+--------------------+------------+-------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_org_type.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_org_stars = df_org_type.groupBy(col(\"username\").alias(\"ORGANIZATION\")).agg(sum(col(\"stars\")).alias(\"TOTAL_STARS\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----------+\n",
      "|      ORGANIZATION|TOTAL_STARS|\n",
      "+------------------+-----------+\n",
      "|              didi|       5144|\n",
      "|          deepmipt|      16875|\n",
      "|          blei-lab|      14079|\n",
      "|            GPflow|       4786|\n",
      "|          twosigma|       6150|\n",
      "|       intel-spark|         91|\n",
      "|     Azure-Samples|       1398|\n",
      "|            seznam|        162|\n",
      "|            kserve|       6946|\n",
      "|           SharpAI|        858|\n",
      "|          Qihoo360|      20409|\n",
      "|          snowlift|         52|\n",
      "|          floydhub|      15620|\n",
      "|         jolibrain|      11656|\n",
      "|    adobe-research|        367|\n",
      "|music-of-the-ainur|         22|\n",
      "|           Alluxio|      22050|\n",
      "|            cdapio|        162|\n",
      "|    USCDataScience|        390|\n",
      "|            cerner|        128|\n",
      "+------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_org_stars.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_org_stars.write.jdbc(url=db_url, table=\"ORGNIZATION_TYPE\", mode=\"overwrite\", properties=db_properties)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SEARCH_TERMS_RELEVENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg = df.groupBy(\"file_name\").agg(\n",
    "    sum(\"forks\").alias(\"total_forks\"),\n",
    "    sum(\"subscribers\").alias(\"total_subscribers\"),\n",
    "    sum(\"stars\").alias(\"total_stars\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_relevance = df_agg.select(\n",
    "    col(\"file_name\").alias(\"search_term\"), \n",
    "    (1.5 * col(\"total_forks\") + 1.32 * col(\"total_subscribers\") + 1.04 * col(\"total_stars\")).alias(\"relevance_score\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------------+\n",
      "| search_term|   relevance_score|\n",
      "+------------+------------------+\n",
      "|       Spark|295286.16000000003|\n",
      "|  Tensorflow|        3918987.26|\n",
      "|      Hadoop|         1168031.8|\n",
      "|      Kotlin|1936763.9000000001|\n",
      "|    React-JS|         870068.36|\n",
      "|         Cpp|4377811.4399999995|\n",
      "|    ethereum|        1157287.26|\n",
      "|      Docker|4403817.5600000005|\n",
      "|       Flask| 884822.1200000001|\n",
      "|     Flutter|              NULL|\n",
      "|       Scala|1287463.6800000002|\n",
      "|     PyTorch|        3357329.08|\n",
      "|React-Native|        3097924.46|\n",
      "|  Typescript|        4909697.76|\n",
      "|           R|     1.187633824E7|\n",
      "|  Kubernetes|3540183.0200000005|\n",
      "|      NodeJS|        4331014.68|\n",
      "|      Scikit|         897061.24|\n",
      "|      Django|1488257.1600000001|\n",
      "|  serverless|        1312038.98|\n",
      "+------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_relevance.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_relevance.write.jdbc(url=db_url, table=\"SEARCH_TERMS_RELEVENCE\", mode=\"overwrite\", properties=db_properties)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
